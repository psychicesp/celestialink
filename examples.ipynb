{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import phenograph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.segmented_svc.segmented_svc import SegmentedSVC\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(\"test\", \"flow_cytometry_test_data.csv\")).sample(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_df = scaler.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 30 nearest neighbors using minkowski metric and 'auto' algorithm\n",
      "Neighbors computed in 58.51398801803589 seconds\n",
      "Jaccard graph constructed in 27.602198362350464 seconds\n",
      "Running Leiden optimization\n",
      "Leiden completed in 630.0765178203583 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 725.9330031871796 seconds\n"
     ]
    }
   ],
   "source": [
    "# Clustering the whole dataset\n",
    "\n",
    "communities, graph, Q  = phenograph.cluster(\n",
    "    scaled_df,\n",
    "    clustering_algo = \"leiden\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the SegmentedSVC to do the same computation in less time\n",
    "\n",
    "#   We need to use unscaled data because the SegmentedSVC object \n",
    "# will train and use its own\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(scaled_df,\n",
    "                                                                    communities,\n",
    "                                                                    train_size=0.8\n",
    "                                                                    )\n",
    "\n",
    "celestia_object = SegmentedSVC(\n",
    "    data = train_data,\n",
    "    labels = train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., 12.,  4., ...,  0.,  8.,  2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = celestia_object.predict(test_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     11100\n",
      "           1       0.95      0.96      0.96      9816\n",
      "           2       0.95      0.95      0.95      9708\n",
      "           3       0.93      0.95      0.94      7661\n",
      "           4       0.94      0.94      0.94      7707\n",
      "           5       0.98      0.98      0.98      7389\n",
      "           6       0.94      0.93      0.94      7051\n",
      "           7       0.95      0.95      0.95      7001\n",
      "           8       0.96      0.97      0.96      3919\n",
      "           9       0.95      0.93      0.94      3785\n",
      "          10       0.96      0.95      0.95      3318\n",
      "          11       0.97      0.97      0.97      2381\n",
      "          12       0.96      0.95      0.95      2353\n",
      "          13       0.95      0.94      0.95      2180\n",
      "          14       0.98      0.98      0.98      1963\n",
      "          15       0.94      0.92      0.93      1752\n",
      "          16       0.98      0.98      0.98      1535\n",
      "          17       0.95      0.91      0.93      1576\n",
      "          18       0.96      0.97      0.97      1484\n",
      "          19       0.91      0.85      0.88      1414\n",
      "          20       0.97      0.98      0.97      1013\n",
      "          21       0.95      0.92      0.94       875\n",
      "          22       0.96      0.96      0.96       655\n",
      "          23       0.98      0.94      0.96       713\n",
      "          24       0.94      0.89      0.91       520\n",
      "          25       0.99      0.96      0.97       263\n",
      "          26       1.00      1.00      1.00       201\n",
      "          27       0.98      0.97      0.97       172\n",
      "          28       0.99      0.98      0.98       147\n",
      "          29       0.98      0.98      0.98       151\n",
      "          30       1.00      0.95      0.97        99\n",
      "          31       1.00      1.00      1.00        50\n",
      "          32       0.97      0.97      0.97        37\n",
      "          33       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.95    100000\n",
      "   macro avg       0.96      0.95      0.95    100000\n",
      "weighted avg       0.95      0.95      0.95    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This default performance has been repeatable to me with a large variety of data set types and complexities,\n",
    "# and blows other classifiers out of the water\n",
    "\n",
    "# (Some of these take a LOONG time, wayy longer than the initial labelling)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    scaled_df.values,\n",
    "    communities,\n",
    "    train_size=0.8\n",
    ")\n",
    "\n",
    "# Pure SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(train_data, train_labels)\n",
    "predicted_labels = classifier.predict(test_data)\n",
    "\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84     10944\n",
      "           1       0.67      0.88      0.76      9726\n",
      "           2       0.69      0.80      0.74      9668\n",
      "           3       0.41      0.54      0.47      7803\n",
      "           4       0.49      0.64      0.56      7738\n",
      "           5       0.63      0.72      0.67      7428\n",
      "           6       0.61      0.59      0.60      7138\n",
      "           7       0.34      0.31      0.32      6827\n",
      "           8       0.12      0.04      0.06      3908\n",
      "           9       0.75      0.76      0.75      3874\n",
      "          10       0.41      0.28      0.33      3409\n",
      "          11       0.77      0.68      0.72      2376\n",
      "          12       0.67      0.53      0.59      2354\n",
      "          13       0.10      0.02      0.04      2218\n",
      "          14       0.43      0.22      0.29      1928\n",
      "          15       0.71      0.57      0.63      1748\n",
      "          16       0.94      0.94      0.94      1573\n",
      "          17       0.22      0.02      0.04      1632\n",
      "          18       0.71      0.56      0.62      1416\n",
      "          19       0.14      0.05      0.07      1374\n",
      "          20       0.94      0.93      0.94      1073\n",
      "          21       0.57      0.16      0.25       895\n",
      "          22       0.21      0.06      0.09       676\n",
      "          23       0.91      0.75      0.83       718\n",
      "          24       0.84      0.71      0.77       510\n",
      "          25       0.68      0.71      0.70       244\n",
      "          26       0.78      0.90      0.83       158\n",
      "          27       0.92      0.94      0.93       165\n",
      "          28       0.66      0.51      0.57       157\n",
      "          29       0.37      0.10      0.16       127\n",
      "          30       0.99      1.00      1.00       106\n",
      "          31       0.24      0.27      0.26        41\n",
      "          32       0.55      0.17      0.26        36\n",
      "          33       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.61    100000\n",
      "   macro avg       0.60      0.54      0.55    100000\n",
      "weighted avg       0.57      0.61      0.58    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(train_data, train_labels)\n",
    "predicted_labels = classifier.predict(test_data)\n",
    "\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     10944\n",
      "           1       0.95      0.96      0.95      9726\n",
      "           2       0.95      0.95      0.95      9668\n",
      "           3       0.94      0.95      0.94      7803\n",
      "           4       0.93      0.94      0.94      7738\n",
      "           5       0.98      0.98      0.98      7428\n",
      "           6       0.94      0.93      0.93      7138\n",
      "           7       0.95      0.95      0.95      6827\n",
      "           8       0.96      0.96      0.96      3908\n",
      "           9       0.95      0.94      0.95      3874\n",
      "          10       0.96      0.96      0.96      3409\n",
      "          11       0.97      0.96      0.97      2376\n",
      "          12       0.94      0.94      0.94      2354\n",
      "          13       0.96      0.95      0.95      2218\n",
      "          14       0.97      0.98      0.98      1928\n",
      "          15       0.93      0.91      0.92      1748\n",
      "          16       0.99      0.97      0.98      1573\n",
      "          17       0.94      0.92      0.93      1632\n",
      "          18       0.95      0.97      0.96      1416\n",
      "          19       0.90      0.86      0.88      1374\n",
      "          20       0.96      0.94      0.95      1073\n",
      "          21       0.93      0.92      0.93       895\n",
      "          22       0.97      0.91      0.94       676\n",
      "          23       0.93      0.90      0.91       718\n",
      "          24       0.93      0.85      0.89       510\n",
      "          25       0.99      0.98      0.99       244\n",
      "          26       1.00      1.00      1.00       158\n",
      "          27       0.94      0.90      0.92       165\n",
      "          28       0.99      0.94      0.96       157\n",
      "          29       0.98      0.79      0.87       127\n",
      "          30       1.00      0.98      0.99       106\n",
      "          31       0.95      0.95      0.95        41\n",
      "          32       1.00      1.00      1.00        36\n",
      "          33       1.00      0.42      0.59        12\n",
      "\n",
      "    accuracy                           0.95    100000\n",
      "   macro avg       0.96      0.92      0.94    100000\n",
      "weighted avg       0.95      0.95      0.95    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(train_data, train_labels)\n",
    "predicted_labels = classifier.predict(test_data)\n",
    "\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     44430\n",
      "           1       0.93      0.95      0.94     38731\n",
      "           2       0.94      0.94      0.94     38502\n",
      "           3       0.91      0.94      0.92     30952\n",
      "           4       0.93      0.92      0.92     30786\n",
      "           5       0.97      0.98      0.97     29879\n",
      "           6       0.93      0.92      0.92     28335\n",
      "           7       0.94      0.94      0.94     27786\n",
      "           8       0.95      0.96      0.96     15680\n",
      "           9       0.95      0.91      0.93     15334\n",
      "          10       0.95      0.94      0.94     13556\n",
      "          11       0.96      0.95      0.96      9431\n",
      "          12       0.93      0.92      0.92      9296\n",
      "          13       0.93      0.94      0.94      8733\n",
      "          14       0.98      0.96      0.97      7692\n",
      "          15       0.93      0.88      0.90      6940\n",
      "          16       0.98      0.98      0.98      6325\n",
      "          17       0.85      0.88      0.87      6238\n",
      "          18       0.96      0.96      0.96      5969\n",
      "          19       0.89      0.81      0.85      5532\n",
      "          20       0.97      0.95      0.96      4326\n",
      "          21       0.94      0.90      0.92      3484\n",
      "          22       0.96      0.93      0.94      2829\n",
      "          23       0.93      0.87      0.90      2780\n",
      "          24       0.95      0.79      0.87      2077\n",
      "          25       0.99      0.97      0.98      1004\n",
      "          26       1.00      0.98      0.99       711\n",
      "          27       0.92      0.92      0.92       701\n",
      "          28       0.98      0.99      0.98       618\n",
      "          29       0.93      0.91      0.92       492\n",
      "          30       1.00      0.94      0.97       446\n",
      "          31       1.00      0.71      0.83       207\n",
      "          32       0.98      0.76      0.86       153\n",
      "          33       1.00      0.27      0.42        45\n",
      "\n",
      "    accuracy                           0.94    400000\n",
      "   macro avg       0.95      0.90      0.92    400000\n",
      "weighted avg       0.94      0.94      0.94    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PS: SegmentedSVC also works just fine with a small train set\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    test_df.values, \n",
    "    communities, \n",
    "    train_size=0.2\n",
    "    )\n",
    "\n",
    "celestia_object = SegmentedSVC(\n",
    "    data = train_data,\n",
    "    labels = train_labels\n",
    ")\n",
    "\n",
    "predicted_labels = celestia_object.predict(test_data)\n",
    "predicted_labels\n",
    "\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest is NOT\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    scaled_df,\n",
    "    communities,\n",
    "    train_size=0.2\n",
    ")\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(train_data, train_labels)\n",
    "predicted_labels = classifier.predict(test_data)\n",
    "\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
