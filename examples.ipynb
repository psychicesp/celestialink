{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import phenograph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.segmented_svc.segmented_svc import SegmentedSVC\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(\"test\", \"flow_cytometry_test_data.csv\")).sample(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_df = scaler.fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding 30 nearest neighbors using minkowski metric and 'auto' algorithm\n",
      "Neighbors computed in 58.51398801803589 seconds\n",
      "Jaccard graph constructed in 27.602198362350464 seconds\n",
      "Running Leiden optimization\n",
      "Leiden completed in 630.0765178203583 seconds\n",
      "Sorting communities by size, please wait ...\n",
      "PhenoGraph completed in 725.9330031871796 seconds\n"
     ]
    }
   ],
   "source": [
    "# Clustering the whole dataset\n",
    "\n",
    "communities, graph, Q  = phenograph.cluster(\n",
    "    scaled_df,\n",
    "    clustering_algo = \"leiden\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the SegmentedSVC to do the same computation in less time\n",
    "\n",
    "#   We need to use unscaled data because the SegmentedSVC object \n",
    "# will train and use its own\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(scaled_df.values,\n",
    "                                                                    communities,\n",
    "                                                                    train_size=0.8\n",
    "                                                                    )\n",
    "\n",
    "celestia_object = SegmentedSVC(\n",
    "    data = train_data,\n",
    "    labels = train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., 12.,  4., ...,  0.,  8.,  2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = celestia_object.predict(test_data)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     11100\n",
      "           1       0.95      0.96      0.96      9816\n",
      "           2       0.95      0.95      0.95      9708\n",
      "           3       0.93      0.95      0.94      7661\n",
      "           4       0.94      0.94      0.94      7707\n",
      "           5       0.98      0.98      0.98      7389\n",
      "           6       0.94      0.93      0.94      7051\n",
      "           7       0.95      0.95      0.95      7001\n",
      "           8       0.96      0.97      0.96      3919\n",
      "           9       0.95      0.93      0.94      3785\n",
      "          10       0.96      0.95      0.95      3318\n",
      "          11       0.97      0.97      0.97      2381\n",
      "          12       0.96      0.95      0.95      2353\n",
      "          13       0.95      0.94      0.95      2180\n",
      "          14       0.98      0.98      0.98      1963\n",
      "          15       0.94      0.92      0.93      1752\n",
      "          16       0.98      0.98      0.98      1535\n",
      "          17       0.95      0.91      0.93      1576\n",
      "          18       0.96      0.97      0.97      1484\n",
      "          19       0.91      0.85      0.88      1414\n",
      "          20       0.97      0.98      0.97      1013\n",
      "          21       0.95      0.92      0.94       875\n",
      "          22       0.96      0.96      0.96       655\n",
      "          23       0.98      0.94      0.96       713\n",
      "          24       0.94      0.89      0.91       520\n",
      "          25       0.99      0.96      0.97       263\n",
      "          26       1.00      1.00      1.00       201\n",
      "          27       0.98      0.97      0.97       172\n",
      "          28       0.99      0.98      0.98       147\n",
      "          29       0.98      0.98      0.98       151\n",
      "          30       1.00      0.95      0.97        99\n",
      "          31       1.00      1.00      1.00        50\n",
      "          32       0.97      0.97      0.97        37\n",
      "          33       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.95    100000\n",
      "   macro avg       0.96      0.95      0.95    100000\n",
      "weighted avg       0.95      0.95      0.95    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This default performance has been repeatable to me with a large variety of data set types and complexities,\n",
    "# and blows other classifiers out of the water\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(test_df.values,\n",
    "                                                                    communities,\n",
    "                                                                    train_size=0.8\n",
    "                                                                    )\n",
    "\n",
    "# Pure SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     44386\n",
      "           1       0.94      0.95      0.94     38962\n",
      "           2       0.94      0.94      0.94     38208\n",
      "           3       0.90      0.95      0.92     30926\n",
      "           4       0.93      0.92      0.92     30763\n",
      "           5       0.97      0.98      0.97     29823\n",
      "           6       0.93      0.92      0.93     28344\n",
      "           7       0.94      0.94      0.94     27951\n",
      "           8       0.95      0.95      0.95     15688\n",
      "           9       0.95      0.91      0.93     15283\n",
      "          10       0.95      0.94      0.95     13540\n",
      "          11       0.96      0.96      0.96      9331\n",
      "          12       0.94      0.92      0.93      9345\n",
      "          13       0.94      0.94      0.94      8758\n",
      "          14       0.97      0.97      0.97      7638\n",
      "          15       0.93      0.88      0.90      6967\n",
      "          16       0.97      0.97      0.97      6343\n",
      "          17       0.88      0.87      0.88      6303\n",
      "          18       0.96      0.95      0.96      5914\n",
      "          19       0.90      0.83      0.86      5537\n",
      "          20       0.97      0.95      0.96      4378\n",
      "          21       0.91      0.90      0.91      3519\n",
      "          22       0.96      0.92      0.94      2831\n",
      "          23       0.96      0.87      0.91      2816\n",
      "          24       0.92      0.81      0.86      2053\n",
      "          25       0.99      0.97      0.98      1009\n",
      "          26       1.00      0.99      0.99       717\n",
      "          27       0.94      0.92      0.93       696\n",
      "          28       0.97      0.97      0.97       615\n",
      "          29       0.90      0.95      0.92       510\n",
      "          30       1.00      0.99      0.99       447\n",
      "          31       1.00      0.78      0.87       202\n",
      "          32       0.98      0.65      0.78       161\n",
      "          33       1.00      0.42      0.59        36\n",
      "\n",
      "    accuracy                           0.94    400000\n",
      "   macro avg       0.95      0.90      0.92    400000\n",
      "weighted avg       0.94      0.94      0.94    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PS: It also works just fine with a small train set\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    test_df.values, \n",
    "    communities, \n",
    "    train_size=0.2\n",
    "    )\n",
    "\n",
    "celestia_object = SegmentedSVC(\n",
    "    data = train_data,\n",
    "    labels = train_labels\n",
    ")\n",
    "\n",
    "predicted_labels = celestia_object.predict(test_data)\n",
    "predicted_labels\n",
    "\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
